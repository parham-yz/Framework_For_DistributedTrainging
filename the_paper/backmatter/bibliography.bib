@inproceedings{langley00,
  author    = {P.~Langley},
  title     = {Crafting Papers on Machine Learning},
  year      = {2000},
  pages     = {1207--1216},
  editor    = {Pat Langley},
  booktitle = {Proceedings of the 17th International Conference on Machine Learning (ICML 2000)},
  address   = {Stanford, CA},
  publisher = {Morgan Kaufmann}
}

@techreport{mitchell80,
  author      = {T.~M. Mitchell},
  title       = {The Need for Biases in Learning Generalizations},
  institution = {Computer Science Department, Rutgers University},
  year        = {1980},
  address     = {New Brunswick, MA}
}

@phdthesis{kearns89,
  author = {M.~J. Kearns},
  title  = {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year   = {1989}
}

@book{MachineLearningI,
  editor    = {R.~S. Michalski and J.~G. Carbonell and T.~M. Mitchell},
  title     = {Machine Learning: An Artificial Intelligence Approach, Vol.~I},
  publisher = {Tioga},
  year      = {1983},
  address   = {Palo Alto, CA}
}

@book{DudaHart2nd,
  author    = {R.~O. Duda and P.~E. Hart and D.~G. Stork},
  title     = {Pattern Classification},
  publisher = {John Wiley and Sons},
  edition   = {2nd},
  year      = {2000}
}

@misc{anonymous,
  title  = {Suppressed for Anonymity},
  author = {Author, N.~N.},
  year   = {2021}
}

@incollection{Newell81,
  author    = {A. Newell and P.~S. Rosenbloom},
  title     = {Mechanisms of Skill Acquisition and the Law of Practice},
  booktitle = {Cognitive Skills and Their Acquisition},
  pages     = {1--51},
  publisher = {Lawrence Erlbaum Associates, Inc.},
  year      = {1981},
  editor    = {J.~R. Anderson},
  chapter   = {1},
  address   = {Hillsdale, NJ}
}

@article{Samuel59,
  author  = {A.~L. Samuel},
  title   = {Some Studies in Machine Learning Using the Game of Checkers},
  journal = {IBM Journal of Research and Development},
  year    = {1959},
  volume  = {3},
  number  = {3},
  pages   = {211--229}
}

@incollection{von2007theory,
  title     = {Theory of Games and Economic Behavior: 60th Anniversary Commemorative Edition},
  author    = {John Von Neumann and Oskar Morgenstern},
  booktitle = {Theory of Games and Economic Behavior},
  year      = {2007},
  publisher = {Princeton University Press}
}

@inproceedings{mcmahan2017communication,
  title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Aguera y Arcas, Blaise},
  booktitle={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@misc{lee2024fundamental,
  title={Fundamental Limits of Gradient Descent--Ascent for Minimax Optimization},
  author={Lee, J. and Chen, X. and Zhang, K.},
  howpublished={arXiv preprint arXiv:2402.01528},
  year={2024}
}

@article{kovalev2022first,
  title={First-Order Methods for Minimax Optimization with Optimal Communication Guarantees},
  author={Kovalev, Dmitry and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2203.07421},
  year={2022}
}

@article{zhang2022near,
  title={Near-Optimal Communication Complexity of Distributed Minimax Optimization},
  author={Zhang, Siqi and Choudhury, Sayantan and Stich, Sebastian U.},
  journal={arXiv preprint arXiv:2210.01557},
  year={2022}
}

@article{popov1980modification,
  title={A Modification of the Arrow--Hurwicz Method for Search of Saddle Points},
  author={Popov, L. M.},
  journal={Mathematical Notes},
  volume={28},
  number={5},
  pages={845--848},
  year={1980}
}

@article{korpelevich1976extragradient,
  title={The Extragradient Method for Finding Saddle Points and Other Problems},
  author={Korpelevich, Galina M.},
  journal={Ekonomika i Matematicheskie Metody},
  volume={12},
  number={4},
  pages={747--756},
  year={1976}
}

@misc{EpochAIModels2025,
  title = {Data on AI Models},
  author = {{Epoch AI}},
  year = {2025},
  month = {07},
  url = {https://epoch.ai/data/ai-models},
  note = {Accessed: 2025-11-24}
}

@article{zhang2022lower,
  title={Lower Bounds for Decentralized Saddle-Point Optimization},
  author={Zhang, Siqi and Stich, Sebastian U.},
  journal={arXiv preprint arXiv:2211.11435},
  year={2022}
}

@book{facchinei2003finite,
  title={Finite-Dimensional Variational Inequalities and Complementarity Problems},
  author={Facchinei, Francisco and Pang, Jong-Shi},
  year={2003},
  publisher={Springer}
}

@article{deng2021local,
  title={Local Stochastic Gradient Descent Ascent for Communication-Efficient Bilevel Learning},
  author={Deng, Yuyang and Chen, Tianyi and Sayed, Ali H.},
  journal={arXiv preprint arXiv:2102.06751},
  year={2021}
}

@article{nouiehed2019solving,
  title={Solving a class of non-convex min-max games using iterative first order methods},
  author={Nouiehed, Maher and Sanjabi, Maziar and Huang, Tianjian and Lee, Jason D and Razaviyayn, Meisam},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{bravo2018bandit,
  title={Bandit learning in concave N-person games},
  author={Bravo, Mario and Leslie, David and Mertikopoulos, Panayotis},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{stich2019unified,
  title={Unified optimal analysis of the (stochastic) gradient method},
  author={Stich, Sebastian U},
  journal={arXiv preprint arXiv:1907.04232},
  year={2019}
}

@article{gershgorin1931uber,
  title={Uber die abgrenzung der eigenwerte einer matrix},
  author={Gershgorin, Semyon Aranovich},
  journal={Известия Российской академии наук. Серия математическая},
  number={6},
  pages={749--754},
  year={1931},
  publisher={Российская академия наук, Математический институт им. ВА Стеклова Российской~…}
}

@article{varga2004springer,
  title={Springer series in computational mathematics},
  author={Varga, Richard S},
  year={2004},
  publisher={Springer}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{yu2019multi,
  title={Multi-agent adversarial inverse reinforcement learning},
  author={Yu, Lantao and Song, Jiaming and Ermon, Stefano},
  booktitle={International Conference on Machine Learning},
  pages={7194--7201},
  year={2019},
  organization={PMLR}
}

@inproceedings{wang2020optimal,
  title={Optimal algorithms for multiplayer multi-armed bandits},
  author={Wang, Po-An and Proutiere, Alexandre and Ariu, Kaito and Jedra, Yassir and Russo, Alessio},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4120--4129},
  year={2020},
  organization={PMLR}
}

@article{agarwal2022multi,
  title={Multi-agent multi-armed bandits with limited communication},
  author={Agarwal, Mridul and Aggarwal, Vaneet and Azizzadenesheli, Kamyar},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={212},
  pages={1--24},
  year={2022}
}

@article{mitra2021exploiting,
  title={Exploiting heterogeneity in robust federated best-arm identification},
  author={Mitra, Aritra and Hassani, Hamed and Pappas, George},
  journal={arXiv preprint arXiv:2109.05700},
  year={2021}
}

@inproceedings{chen2023demand,
  title={On-demand communication for asynchronous multi-agent bandits},
  author={Chen, Yu-Zhen Janice and Yang, Lin and Wang, Xuchuang and Liu, Xutong and Hajiesmaili, Mohammad and Lui, John CS and Towsley, Don},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3903--3930},
  year={2023},
  organization={PMLR}
}

@article{loizou2021stochastic,
  title={Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity},
  author={Loizou, Nicolas and Berard, Hugo and Gidel, Gauthier and Mitliagkas, Ioannis and Lacoste-Julien, Simon},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19095--19108},
  year={2021}
}


@article{zhu2019deep,
  title={Deep leakage from gradients},
  author={Zhu, Ligeng and Liu, Zhijian and Han, Song},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@article{zhao2020idlg,
  title={idlg: Improved deep leakage from gradients},
  author={Zhao, Bo and Mopuri, Konda Reddy and Bilen, Hakan},
  journal={arXiv preprint arXiv:2001.02610},
  year={2020}
}


@article{wei2020framework,
  title={A framework for evaluating gradient leakage attacks in federated learning},
  author={Wei, Wenqi and Liu, Ling and Loper, Margaret and Chow, Ka-Ho and Gursoy, Mehmet Emre and Truex, Stacey and Wu, Yanzhao},
  journal={arXiv preprint arXiv:2004.10397},
  year={2020}
}


@article{robey2023adversarial,
  title={Adversarial training should be cast as a non-zero-sum game},
  author={Robey, Alexander and Latorre, Fabian and Pappas, George J and Hassani, Hamed and Cevher, Volkan},
  journal={arXiv preprint arXiv:2306.11035},
  year={2023}
}


@inproceedings{lin2020near,
  title={Near-optimal algorithms for minimax optimization},
  author={Lin, Tianyi and Jin, Chi and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2738--2779},
  year={2020},
  organization={PMLR}
}

@inproceedings{mokhtari2020unified,
  title={A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach},
  author={Mokhtari, Aryan and Ozdaglar, Asuman and Pattathil, Sarath},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1497--1507},
  year={2020},
  organization={PMLR}
}

@inproceedings{khaled2020tighter,
  title={Tighter theory for local SGD on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}

@article{patel2024limits,
  title={The limits and potentials of local sgd for distributed heterogeneous learning with intermittent communication},
  author={Patel, Kumar Kshitij and Glasgow, Margalit and Zindari, Ali and Wang, Lingxiao and Stich, Sebastian U and Cheng, Ziheng and Joshi, Nirmit and Srebro, Nathan},
  journal={arXiv preprint arXiv:2405.11667},
  year={2024}
}

@inproceedings{balduzzi2018mechanics,
  title={The Mechanics of n-Player Differentiable Games},
  author={Balduzzi, David and Racaniere, Sebastien and Martens, James and Foerster, Jakob and Tuyls, Karl and Graepel, Thore},
  booktitle={ICML},
  year={2018}
}

@ARTICLE{drone_two-pl,
  author={Spica, Riccardo and Cristofalo, Eric and Wang, Zijian and Montijano, Eduardo and Schwager, Mac},
  journal={IEEE Transactions on Robotics}, 
  title={A Real-Time Game Theoretic Planner for Autonomous Two-Player Drone Racing}, 
  year={2020},
  volume={36},
  number={5},
  pages={1389-1403},
  doi={10.1109/TRO.2020.2994881}
}

@INPROCEEDINGS{motion_plan,
  author={Laine, Forrest and Fridovich-Keil, David and Chiu, Chih-Yuan and Tomlin, Claire},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Multi-Hypothesis Interactions in Game-Theoretic Motion Planning}, 
  year={2021},
  volume={},
  number={},
  pages={8016-8023},
  doi={10.1109/ICRA48506.2021.9561695}}


@article{lowe2017multi,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

@inproceedings{zindari2023convergence,
  title={On the convergence of local SGD under third-order smoothness and hessian similarity},
  author={Zindari, Ali and Luo, Ruichen and Stich, Sebastian U},
  booktitle={OPT 2023: Optimization for Machine Learning},
  year={2023}
}

@article{uav_asisted,
  author       = {Mi Zhou and
                  Yue Guan and
                  Mohammad Hayajneh and
                  Kaicheng Niu and
                  Chaouki T. Abdallah},
  title        = {Game Theory and Machine Learning in UAVs-Assisted Wireless Communication
                  Networks: {A} Survey},
  journal      = {Arxiv:2108.03495},
  year         = {2021},
}

@article{meena2022,
  journal = {ArXiv:2208.14423},
  author = {Jagadeesan, Meena and Jordan, Michael I. and Haghtalab, Nika},
  title = {Competition, Alignment, and Equilibria in Digital Marketplaces},
  year = {2022},
}

@article{lifted2022,
      title={Lifted Primal-Dual Method for Bilinearly Coupled Smooth Minimax Optimization}, 
      author={Kiran Koshy Thekumparampil and Niao He and Sewoong Oh},
      year={2022},
      journal={AISTATS},
}

@article{zhang2021,
  author       = {Guodong Zhang and
                  Yuanhao Wang and
                  Laurent Lessard and
                  Roger B. Grosse},
  title        = {Don't Fix What ain't Broke: Near-optimal Local Convergence of Alternating
                  Gradient Descent-Ascent for Minimax Optimization},
  journal      = {arXiv:2102.09468},
  year         = {2021},
}


@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}


@mastersthesis{cifar10,
    author = {Krizhevsky, Alex},
    keywords = {learning, sparse},
    title = {{Learning Multiple Layers of Features from Tiny Images}},
    year = {2009}
}

@article{svhn,
   author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo  and Y. Ng, Andrew},
    title = {Reading Digits in Natural Images with Unsupervised Feature Learning},
    booktitile = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning},
    url = {http://ufldl.stanford.edu/housenumbers/},
    year = {2011}
}

@article{tsaknakis2021minimax,
  title={Minimax problems with coupled linear constraints: computational complexity, duality and solution methods},
  author={Tsaknakis, Ioannis and Hong, Mingyi and Zhang, Shuzhong},
  journal={arXiv preprint arXiv:2110.11210},
  year={2021}
}

@article{tseng2009coordinate,
  title={A coordinate gradient descent method for nonsmooth separable minimization},
  author={Tseng, Paul and Yun, Sangwoon},
  journal={Mathematical Programming},
  volume={117},
  pages={387--423},
  year={2009},
  publisher={Springer}
}

@inproceedings{jain2018accelerating,
  title={Accelerating stochastic gradient descent for least squares regression},
  author={Jain, Prateek and Kakade, Sham M and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle={Conference On Learning Theory},
  pages={545--604},
  year={2018},
  organization={PMLR}
}

@inproceedings{yoon2021accelerated,
  title={Accelerated Algorithms for Smooth Convex-Concave Minimax Problems with $O(1/k^2)$ Rate on Squared Gradient Norm},
  author={Yoon, TaeHo and Ryu, Ernest K},
  booktitle={International Conference on Machine Learning},
  pages={12098--12109},
  year={2021},
  organization={PMLR}
}



@inproceedings{azizian2020accelerating,
  title={Accelerating smooth games by manipulating spectral shapes},
  author={Azizian, Waïs and Scieur, Damien and Mitliagkas, Ioannis and Lacoste-Julien, Simon and Gidel, Gauthier},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1705--1715},
  year={2020},
  organization={PMLR}
}

@article{yuan2020federated,
  title={Federated accelerated stochastic gradient descent},
  author={Yuan, Honglin and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5332--5344},
  year={2020}
}

@article{yoon2025multiplayer,
  title={Multiplayer Federated Learning: Reaching Equilibrium with Less Communication},
  author={Yoon, TaeHo and Choudhury, Sayantan and Loizou, Nicolas},
  journal={arXiv preprint arXiv:2501.08263},
  year={2025}
}

@inproceedings{lu2021decentralized,
  title={Decentralized policy gradient descent ascent for safe multi-agent reinforcement learning},
  author={Lu, Songtao and Zhang, Kaiqing and Chen, Tianyi and Ba{\c{s}}ar, Tamer and Horesh, Lior},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={10},
  pages={8767--8775},
  year={2021}
}


@article{jiang2022i2q,
  title={I2Q: A fully decentralized Q-learning algorithm},
  author={Jiang, Jiechuan and Lu, Zongqing},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20469--20481},
  year={2022}
}

@article{sayin2021decentralized,
  title={Decentralized Q-learning in zero-sum Markov games},
  author={Sayin, Muhammed and Zhang, Kaiqing and Leslie, David and Basar, Tamer and Ozdaglar, Asuman},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={18320--18334},
  year={2021}
}

@inproceedings{zindari2024decoupled,
  title={Decoupled Stochastic Gradient Descent for N-Player Games},
  author={Zindari, Ali and Yazdkhasti, Parham and Chavdarova, Tatjana and Stich, Sebastian U},
  booktitle={ICML 2024 Workshop: Aligning Reinforcement Learning Experimentalists and Theorists},
  year={2024}
}

@inproceedings{
zhang2024communicationefficient,
title={Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates},
author={Siqi Zhang and Sayantan Choudhury and Sebastian U Stich and Nicolas Loizou},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}


@InProceedings{pmlr-v54-mcmahan17a,
  title = 	 {{Communication-Efficient Learning of Deep Networks from Decentralized Data}},
  author = 	 {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera y},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1273--1282},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 apr,
  note =       {Held 20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/mcmahan17a.html},
  abstract = 	 {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches.  We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning.  We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent. }
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{liu2024deepseek,
  title={Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model},
  author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@misc{chen2022training,
  title={Training giant neural networks using pipeline parallelism},
  author={Chen, Zhifeng and Huang, Yanping and Cheng, Youlong and Lee, HyoukJoong and Chen, Dehao and Ngiam, Jiquan},
  year={2022},
  date = {2022-01-25},
  publisher={Google Patents},
  note={US Patent 11,232,356}
}

@article{harlap2018pipedream,
  title={Pipedream: Fast and efficient pipeline parallel dnn training},
  author={Harlap, Aaron and Narayanan, Deepak and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil and Ganger, Greg and Gibbons, Phil},
  journal={arXiv preprint arXiv:1806.03377},
  year={2018}
}

@article{guan2024advances,
  title={Advances of pipeline model parallelism for deep learning training: an overview},
  author={Guan, Lei and Li, Dong-Sheng and Liang, Ji-Ye and Wang, Wen-Jian and Ge, Ke-Shi and Lu, Xi-Cheng},
  journal={Journal of Computer Science and Technology},
  volume={39},
  number={3},
  pages={567--584},
  year={2024},
  publisher={Springer}
}

@article{liang2024resource,
  title={Resource allocation and workload scheduling for large-scale distributed deep learning: A survey},
  author={Liang, Feng and Zhang, Zhen and Lu, Haifeng and Li, Chengming and Leung, Victor and Guo, Yanyi and Hu, Xiping},
  journal={arXiv preprint arXiv:2406.08115},
  year={2024}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{luo2024badam,
  title={BAdam: A memory efficient full parameter optimization method for large language models},
  author={Luo, Qijun and Yu, Hengxu and Li, Xiao},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={24926--24958},
  year={2024}
}

@article{pan2024lisa,
  title={Lisa: Layerwise importance sampling for memory-efficient large language model fine-tuning},
  author={Pan, Rui and Liu, Xiang and Diao, Shizhe and Pi, Renjie and Zhang, Jipeng and Han, Chi and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={57018--57049},
  year={2024}
}

@inproceedings{nesterov1983method,
  title={A method for solving the convex programming problem with convergence rate O (1/k2)},
  author={Nesterov, Yurii},
  booktitle={Dokl akad nauk Sssr},
  volume={269},
  pages={543},
  year={1983}
}

@article{colin2019theoretical,
  title={Theoretical limits of pipeline parallel optimization and application to distributed deep learning},
  author={Colin, Igor and Dos Santos, Ludovic and Scaman, Kevin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@misc{llama3scaling,
  author = {AI and Systems Co-Design},
  title = {Scaling Llama 3 Training with Efficient Parallelism Strategies},
  year = {2024},
  howpublished = {\url{https://aisystemcodesign.github.io/papers/Llama3-ISCA25.pdf}},
  note = {Accessed: 2025-02-14}
}
 @article{sun2025curse,
   title={The Curse of Depth in Large Language Models},
   author={Sun, Y. and others},
   journal={arXiv:2502.05795},
   year={2025}
 }

@article{richtarik2016parallel,
  title={Parallel coordinate descent methods for big data optimization},
  author={Richt{\'a}rik, Peter and Takac, Martin},
  journal={Mathematical Programming},
  volume={156},
  number={1},
  pages={433--484},
  year={2016},
  publisher={Springer}
}

@article{fercoq2015accelerated,
  title={Accelerated, parallel, and proximal coordinate descent},
  author={Fercoq, Olivier and Richt{\'a}rik, Peter},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={4},
  pages={1997--2023},
  year={2015},
  publisher={SIAM}
}

@article{mutny2018parallel,
  title={Parallel stochastic Newton method},
  author={Mutn{\`y}, Mojm{\'\i}r and Richt{\'a}rik, Peter},
  journal={Journal of Computational Mathematics},
  pages={404--425},
  year={2018},
  publisher={JSTOR}
}

@article{tappenden2018complexity,
  title={On the complexity of parallel coordinate descent},
  author={Tappenden, Rachael and Takac, Martin and Richt{\'a}rik, Peter},
  journal={Optimization Methods and Software},
  volume={33},
  number={2},
  pages={372--395},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{wright2015coordinate,
  title={Coordinate descent algorithms},
  author={Wright, Stephen J},
  journal={Mathematical programming},
  volume={151},
  number={1},
  pages={3--34},
  year={2015},
  publisher={Springer}
}

@article{richtarik2014iteration,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Takac, Martin},
  journal={Mathematical Programming},
  volume={144},
  number={1},
  pages={1--38},
  year={2014},
  publisher={Springer}
}

@article{hsieh2015passcode,
  title={Communication-efficient distributed dual coordinate ascent},
  author={Jaggi, Martin and Smith, Virginia and Tak{\'a}c, Martin and Terhorst, Jonathan and Krishnan, Sanjay and Hofmann, Thomas and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{smith2018cocoa,
  title={CoCoA: A general framework for communication-efficient distributed optimization},
  author={Smith, Virginia and Forte, Simone and Ma, Chenxin and Tak{\'a}{\v{c}}, Martin and Jordan, Michael I and Jaggi, Martin},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={230},
  pages={1--49},
  year={2018}
}


@article{jaggi2014communication,
  title={Communication-efficient distributed dual coordinate ascent},
  author={Jaggi, Martin and Smith, Virginia and Tak{\'a}c, Martin and Terhorst, Jonathan and Krishnan, Sanjay and Hofmann, Thomas and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
