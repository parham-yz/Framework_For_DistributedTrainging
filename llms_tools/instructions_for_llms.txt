LLMs Tooling Guide for This Repository
=====================================

This `llms_tools/` directory provides helper scripts and guidance for parsing and
analyzing experimental results produced by `src/dol1.py` runs (e.g., CNN on MNIST).

Files:
------
- parse_reports.py: Python script to scan `reports/` for completed runs,
  filter by model & dataset, and compute ‚Äúrounds to convergence‚Äù based on
  accuracy or loss thresholds. Outputs a Markdown table.
- instructions_for_llms.txt: This guidance document.

Directory Layout:
-----------------
<repo_root>/
  ‚îî‚îÄ reports/          # Generated bydol1.py (e.g., R<hash>.txt)
  ‚îî‚îÄ llms_tools/       # Helper tools for LLMs and scripts
       ‚îú‚îÄ parse_reports.py
       ‚îî‚îÄ instructions_for_llms.txt

How to Run Experiments:
-----------------------
1. Launch training with `src/dol1.py`. For CNN on MNIST:
   ```bash
   python3 -m src.dol1 \
     --model cnn \
     --dataset_name MNIST \
     --rounds 5000 \
     --K <value> \
     --batch_size 128 \
     --step_size 0.001 \
     --training_mode entire \
     --cuda_core 0  \
     --report_sampling_rate 20
   ```
2. After runs complete, check generated reports in `reports/`:
   - Files named `R<8hex>.txt`.
   - First lines contain `Hyperparameters: { ... }` JSON.
   - Subsequent lines are timestamped logs of training steps.

How parse_reports.py Works:
--------------------------
1. It scans all `R*.txt` files in `reports/`.
2. Parses the JSON hyperparameters under `Hyperparameters:`.
3. Selects only those with `model` == `cnn`  (or `cnn_ensemble`) and `dataset_name` == `MNIST`.
4. Searches each log for lines matching a configurable regex:
   ```python
   metric_line_pattern = re.compile(
       r'Epoch\s*(?P<epoch>\d+).*'
       r'(loss=(?P<loss>[0-9\.]+)).*'
       r'(acc=(?P<acc>[0-9\.]+))'
   )
   ```
5. Determines convergence as first epoch where `acc >= acc_threshold`
   or `loss <= loss_threshold` (thresholds are CLI args).
6. Aggregates across runs of the same `K`, taking the minimum rounds.
7. Emits `llms_tools/cnn_MNIST_summary.md` as a Markdown table.
   - The table has columns: `K`, `Best` (best rounds across all step sizes), followed by one column per step size (showing rounds to convergence for that lr).

Customization Tips:
------------------
- To change convergence criteria, adjust `--acc_threshold` or `--loss_threshold` 
  when invoking parse_reports.py.
- To support other models/datasets, modify the filters in
  `parse_report()` (e.g., `model`, `dataset_name`).
- To adapt to log formats, update `metric_line_pattern` regex to capture the fields.

Notes for LLMs:
---------------
- Hyperparameters are stored in each report under a JSON dict in the
  `Hyperparameters:` line. Keys include `model`, `dataset_name`, `K`, `step_size`, etc.
- Report filenames are content-addressed (first 8 hex of an MD5 of H).
- All `reports/` live at the repo root; this script references them via
  `os.path.join(repo_root, 'reports')`.
- If you extend or build on these tools, ensure your paths and regex patterns
  align with how new experiments log their data.

Happy data wrangling!

General Launch Script Guidelines:
- Consolidate all experiment batches into a single launch script rather than separate files per batch.
- Use shell `wait` commands to ensure one batch finishes before starting the next.
- Include printed progress updates, e.g., "[i/TOTAL] Launching..." and "Batch X complete (i/TOTAL done)".
- Do not auto-execute the launch script; prepare it and await user invocation.
- Choose hyperparameters (e.g., step sizes) thoughtfully based on the task and dataset.

Experiment Batches:
------------------
To run CNN-on-MNIST experiments in controlled batches (max 4 experiments per GPU):
1. Batch 1 (K=1 and K=2):
   - Script: `llms_tools/experiment_batches/batch1.sh`
   - Launches 3 step-size variants for K=1 (entire) on GPU0 and K=2 (blockwise_sequential) on GPU1.
   - Usage: `bash llms_tools/experiment_batches/batch1.sh`
   - Waits until all jobs complete, then prints "Batch 1 complete.".
   - After completion, obtain user confirmation before running batch 2.
2. Batch 2 (K=5 and K=10):
   - Script: `llms_tools/experiment_batches/batch2.sh`
   - Launches 3 step-size variants for K=5 on GPU0 and K=10 on GPU1, both blockwise_sequential.
   - Usage: `bash llms_tools/experiment_batches/batch2.sh`
   - Waits until completion and prints "Batch 2 complete.".

Grid Search for CIFAR-100 (ResNet18):
3. Combined Grid (K=[1,2,5,10,50], step sizes [0.1,0.01,0.001,0.0005,0.0001]):
   - Script: `llms_tools/experiment_batches/cifar100_resnet18_grid.sh`
   - For each K, launches 5 step-size experiments in parallel (distributed over GPUs 0 and 1), then waits.
   - Prints progress as "[i/TOTAL] Launching..." and "Batch K=x complete (i/TOTAL done)".
   - Usage: `bash llms_tools/experiment_batches/cifar100_resnet18_grid.sh`
   - Total experiments: 25. Each batch ensures the previous K finishes before starting the next.

Remember: Don't overload GPUs, and confirm between batches.

------------------------------------------------------------------------

CLI cheat‚Äësheet for¬†`src/dol1.py`
=================================

`dol1.py` is the **single‚Äërun entry point** of the framework.  Every key of
its default hyper‚Äëparameter dictionary¬†`H` automatically becomes a command‚Äëline
flag via the helper `utils.parse_arguments()`.  Below is a *non‚Äëexhaustive*
overview of the most important switches you will encounter in the batch
scripts (`lunch*.bash`) or when crafting ad‚Äëhoc prompts.

| Flag | Type | Typical values | Meaning |
|------|------|----------------|---------|
| `--model` | str | `cnn`, `ResNet18`, `ResNet34`, `residual_cnn`, `cnn_ensemble` | Which architecture loader in `src/Architectures/` to call. |
| `--dataset_name` | str | `mnist`, `cifar10`, `cifar100`, `svhn`, `mini_imagenet` | Passed to `utils.generate_data()` which downloads & preprocesses accordingly. |
| `--training_mode` | str | `entire`, `blockwise_sequential`, `blockwise` (distributed) | ‚Ä¢ *entire*¬†= classic SGD on the full model.<br>‚Ä¢ *blockwise_sequential*¬†= iterate over blocks in one process.<br>‚Ä¢ *blockwise*¬†= spawn one worker per block (multi‚Äëprocess). |
| `--K` | int | `0`, `1`, `2`, ‚Ä¶ | Number of **local optimisation steps per block** before synchronisation.<br>`0` is a special case used by the batch scripts to denote the *entire* baseline. |
| `--step_size` | float | `1e‚Äë3`, `5e‚Äë5`, ‚Ä¶ | Learning‚Äërate / step‚Äësize that is forwarded to the optimiser inside the engines. |
| `--batch_size` | int | `128`, auto‚Äëtuned | Mini‚Äëbatch size; see `utils.get_max_batch_size()` for a dynamic alternative. |
| `--rounds` | int | `5000`, `2000`, ‚Ä¶ | Maximum number of optimisation rounds / epochs. |
| `--cuda_core` | int | `0`, `1`, ‚Ä¶ | GPU index that will host the **centre model**; block workers inherit the same device unless overridden. |
| `--report_sampling_rate` | int | `20`, `5`, ‚Ä¶ | Every *N* rounds the engine calls `Reporter.log_progress()` which ends up in `reports/R*.txt`. |
| `--measurement_sampling_rate` | int | `399`, `799`, ‚Ä¶ | Frequency for the plug‚Äëin *measurement units* defined in `measurements/Units.txt`. |
| `--communication_delay` | float | `0`, `0.1`, ‚Ä¶ | Artificial pause (in **seconds**) inserted after each synchronisation in distributed runs ‚Äì handy for simulating slow networks. |
| `--n_workers` | int | `1`, `4`, ‚Ä¶ | Upper bound on concurrently active Python processes in the distributed engine; useful on multi‚ÄëGPU servers. |
| `--beta` | float | `0.5`, `1.0` | Residual weighting for `residual_cnn` variants. |
| `--config` | JSON list | `"[16,16,32]"` | Layer/channel sizes for the feed‚Äëforward loaders. Pass as **quoted** JSON on the CLI. |

Any extra key you add to the *default*¬†`H` dictionary will magically appear as
another `--flag` ‚Äì a convenient pattern to prototype new ideas without editing
argument‚Äëparsing boilerplate.

Example ‚Äì¬†ResNet34, CIFAR‚Äë100 baseline:
```bash
python -m src.dol1 \
       --model ResNet34 \
       --dataset_name cifar100 \
       --training_mode entire \
       --step_size 5e-5 \
       --batch_size 128 \
       --rounds 5000 \
       --cuda_core 0 \
       --report_sampling_rate 20
```

------------------------------------------------------------------------

Code structure at a glance
==========================

While the main `README.md` gives a detailed tour, the table below is a quick
reference that LLMs can embed in their responses when asked *‚Äúwhere do I change
X?‚Äù*.

| Path | Purpose | Key symbols / notes |
|------|---------|---------------------|
| `src/utils.py` | Misc. helper functions ‚Äì CLI parsing, data loading, GPU probing, the `Reporter`. | `parse_arguments`, `generate_data`, `Reporter` |
| `src/Architectures/` | All network definitions and thin *loader* wrappers. | `feedforward_nn.py`, `resnets.py`, `Models.py` |
| `src/Buliding_Units/MeasurementUnit.py` | Plug‚Äëin interface for run‚Äëtime measurements that operate on the `Frame`. | `Hessian_measurement`, `Working_memory_usage`, ‚Ä¶ |
| `src/Buliding_Units/StopperUnit.py` | Early‚Äëstop criteria (patience, accuracy target, ‚Ä¶). | `AccuracyTargetStopper` |
| `src/Buliding_Units/Model_frames.py` | Runtime containers that own **models + data loaders + plugins**. | `ImageClassifier_frame_blockwise`, `generate_ModelFrame` |
| `src/Optimizer_Engines/` | Actual training loops (entire, sequential, distributed). | `train_entire`, `train_blockwise_sequential`, `train_blockwise_distributed` in `BCD_engine.py` |
| `dol1.py` | Single‚Äërun launcher; builds `Frame`, selects engine, wires up plugins. | executes one experiment |
| `master.py` | Queue¬†& GPU‚Äëaware batch launcher across many experiments. | keeps `progress_tracker.json` |
| `measurements/` | Text logs & config file `Units.txt` for measurement plugins. | editable without touching code |
| `figures/` | Auto‚Äëgenerated visuals (e.g. Hessian heat‚Äëmaps). | created by measurement units |
| `llms_tools/` | Small utilities aimed at post‚Äëprocessing and batch orchestration. | current file, `parse_reports.py`, batch scripts |

------------------------------------------------------------------------

With this reference in place, you (or an obedient LLM) should be able to craft
new experiment batches, extend the metric parsing, or navigate the code base
without digging through every file.  Have fun tinkering! üöÄ